# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
from sentence_transformers import SentenceTransformer
from sklearn.cluster import KMeans
from scipy.stats import chi2_contingency
import numpy as np
from sklearn.decomposition import PCA
from matplotlib import font_manager
import urllib.request
import os
import plotly.express as px

file_path = 'ê¸‰ì‹ ì„¤ë¬¸ì¡°ì‚¬ ì „ì²´-1.csv'
df = pd.read_csv(file_path, encoding='utf-8')

st.write('ê¸‰ì‹ ì„¤ë¬¸ì¡°ì‚¬ ì‘ë‹µ ê²°ê³¼/ê²°ê³¼ ë¶„ì„')

# ê°ê´€ì‹ í•­ëª© ì‹œê°í™”
objective_columns = ['í•™ë…„']
for col in objective_columns:
    if col in df.columns:
        value_counts = df[col].value_counts().reset_index()
        value_counts.columns = [col, 'ì‘ë‹µ ìˆ˜']
        fig = px.bar(value_counts, x=col, y='ì‘ë‹µ ìˆ˜', title=f'{col} ì‘ë‹µ ë¶„í¬')
        st.plotly_chart(fig)

for col in ['ì´ë²ˆì£¼ ë§Œì¡±ë„']:
    if col in df.columns:
        pie_data = df[col].value_counts().reset_index()
        pie_data.columns = [col, 'ë¹„ìœ¨']
        fig = px.pie(pie_data, names=col, values='ë¹„ìœ¨', title=f'{col} ë¹„ìœ¨', hole=0.4)
        st.plotly_chart(fig)

objective_columns = ['ì”ë°˜ ë¹„ìœ¨', 'ìˆ˜ë©´ì‹œê°„']
for col in objective_columns:
    if col in df.columns:
        value_counts = df[col].value_counts().reset_index()
        value_counts.columns = [col, 'ì‘ë‹µ ìˆ˜']
        fig = px.bar(value_counts, x=col, y='ì‘ë‹µ ìˆ˜', title=f'{col} ì‘ë‹µ ë¶„í¬')
        st.plotly_chart(fig)
        
# íŒŒì´ ì°¨íŠ¸ ì‹œê°í™”
for col in ['ì´ë²ˆì£¼ ê¸‰ì‹ì´ ì¢‹ì•˜ë˜ ì´ìœ ','ê¸‰ì‹ì„ ë¨¹ì§€ ì•Šì€ ì´ìœ ','ì•„ì¹¨ë°¥']:
    if col in df.columns:
        pie_data = df[col].value_counts().reset_index()
        pie_data.columns = [col, 'ë¹„ìœ¨']
        fig = px.pie(pie_data, names=col, values='ë¹„ìœ¨', title=f'{col} ë¹„ìœ¨', hole=0.4)
        st.plotly_chart(fig)

# ---------------------- ì‚¬ìš©ì ì„¤ì • ----------------------
week1_menus = [
    "ì›”ìš”ì¼ - ë§ˆë¼íƒ•, ë¯¸ë‹ˆìœ¡ì „, ì´ˆì½”ìš°ìœ ",
    "í™”ìš”ì¼ - ìˆœëŒ€êµ­, ëŒ€êµ¬ê¹ŒìŠ¤, íŒŒì¸ì• í”Œ",
    "ìˆ˜ìš”ì¼ - ì¹˜í‚¨ê¿”ë°”ë¡œìš°, ì°¹ìŒ€ì•½ê³¼",
    "ëª©ìš”ì¼ - ì°¹ìŠ¤í…Œì´í¬, ì‚°ì–‘ìš”êµ¬ë¥´íŠ¸",
    "ê¸ˆìš”ì¼ - ì°¸ì¹˜ë§ˆìš”ë®ë°¥, í¬ë¦¬ìŠ¤í”¼ ë‘ë¶€ìŠ¤í‹±, ê¹”ë¼ë§Œì‹œë ˆëª¬ì—ì´ë“œ"
]

week2_menus = [
    "ì›”ìš”ì¼ - ì „ì£¼ì‹ì½©ë‚˜ë¬¼êµ­ë°¥, ëœì¥ë¶ˆê³ ê¸°, ë°”ë‚˜ë‚˜ìš°ìœ ",
    "í™”ìš”ì¼ - ëƒ‰ë©”ë°€êµ­ìˆ˜, ì•Œë°¥, ëˆê°€ìŠ¤, íƒ€ì½”ì•¼ë¼, ì£¼ìŠ¤",
    "ìˆ˜ìš”ì¼ - ìœ¡ê°œì¥, íƒ•í‰ì±„, ì›…ë–¡ì›…ë–¡, ë¼ì„ë ˆëª¬ì£¼ìŠ¤",
    "ëª©ìš”ì¼ - ì¹´ë ˆë¼ì´ìŠ¤, ì™•ë§Œë‘, íë¸Œì¹´í”„ë ˆì œ, ê°ììŠ¤ë‚µ",
    "ê¸ˆìš”ì¼ - ë¶€ëŒ€ì°Œê°œ, ë‹­ë´‰ë°ë¦¬ì•¼ë¼êµ¬ì´, ìš”êµ¬ë¥´íŠ¸(ì• í”Œë§ê³ )"
]

week3_menus = [
    "ì›”ìš”ì¼ - ìƒˆìš°ë² ì´ì»¨ë³¶ìŒë°¥, ê°ììƒëŸ¬ë“œ, ëª¨ë‹ë¹µ, ìëª½ì—ì´ë“œ", 
    "í™”ìš”ì¼ - ëŒ€íŒ¨ì‚¼ê²¹ë²„ì„¯êµ¬ì´, ìš”êµ¬ë¥´íŠ¸", 
    "ìˆ˜ìš”ì¼ - ì”ì¹˜êµ­ìˆ˜, ì˜¤ë¦¬ì£¼ë¬¼ëŸ­, íŒŒì¸ì• í”Œ",
    "ëª©ìš”ì¼ - ê°ˆë¹„íƒ•, ì˜¤ì§•ì–´ê¹€ì¹˜ì „, ë³µìˆ­ì•„ì£¼ìŠ¤",
    "ê¸ˆìš”ì¼ - ë‹­ê°ˆë¹„, ì´ìƒí•œë‚˜ë¼ì˜ì†œì‚¬íƒ•ì•„ì´ìŠ¤í¬ë¦¼"
]

def extract_weekday_and_menu(text):
    match = re.match(r'(ì›”ìš”ì¼|í™”ìš”ì¼|ìˆ˜ìš”ì¼|ëª©ìš”ì¼|ê¸ˆìš”ì¼)\s*-\s*(.+)', text.strip())
    if match:
        return match.group(1), match.group(2)
    return 'ê¸°íƒ€', text.strip()

def filter_by_week(menus, target_column):
    return target_column[target_column.apply(lambda x: any(menu in x for menu in menus))]

def plot_weekday_meals(df, column_name, week_num, menus, title):
    menu_col = df[column_name].dropna().astype(str)
    week_filtered = filter_by_week(menus, menu_col)

    # ìš”ì¼-ì‹ë‹¨ ì¶”ì¶œ
    weekday_menu_list = week_filtered.apply(extract_weekday_and_menu)
    weekdays = [w for w, _ in weekday_menu_list]
    meals = [m for _, m in weekday_menu_list]

    df_plot = pd.DataFrame({
        'ìš”ì¼': weekdays,
        'ì‹ë‹¨': meals
    })

    # ìš”ì¼ ìˆœì„œ ê³ ì •
    weekday_order = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼']
    df_plot['ìš”ì¼'] = pd.Categorical(df_plot['ìš”ì¼'], categories=weekday_order, ordered=True)

    # ìš”ì¼ë³„ ì‹ë‹¨ ê·¸ë£¹ë³„ ì‘ë‹µ ìˆ˜ ì§‘ê³„
    count_df = df_plot.groupby(['ìš”ì¼', 'ì‹ë‹¨'], as_index=False).size()

    # ğŸ§© ëˆ„ë½ëœ ìš”ì¼ ì±„ìš°ê¸° ìœ„í•œ ë³´ì™„ ë¡œì§
    if not count_df.empty:
        # ëˆ„ë½ ìš”ì¼-ì‹ë‹¨ ì¡°í•© ë³´ì™„
        existing_pairs = set(zip(count_df['ìš”ì¼'], count_df['ì‹ë‹¨']))
        full_pairs = set((day, meal) for day in weekday_order for meal in df_plot['ì‹ë‹¨'].unique())

        missing_pairs = full_pairs - existing_pairs
        if missing_pairs:
            fill_rows = pd.DataFrame(missing_pairs, columns=['ìš”ì¼', 'ì‹ë‹¨'])
            fill_rows['size'] = 0
            count_df = pd.concat([count_df, fill_rows], ignore_index=True)

    # ì‹œê°í™”
    fig = px.bar(
        count_df,
        x='ìš”ì¼',
        y='size',
        color='ì‹ë‹¨',
        hover_data={'ì‹ë‹¨': True, 'size': True, 'ìš”ì¼': False},
        title=f"[{week_num}ì£¼ì°¨] {title}",
        labels={'ìš”ì¼': 'ìš”ì¼', 'size': 'ì‘ë‹µ ìˆ˜'}
    )
    fig.update_layout(xaxis_title='ìš”ì¼', yaxis_title='ì‘ë‹µ ìˆ˜', showlegend=False)
    st.plotly_chart(fig, use_container_width=True)

# ---------------------- Streamlit ì‹¤í–‰ ì˜ì—­ ----------------------
st.title("ê¸‰ì‹ ë§Œì¡±ë„-ì´ë²ˆì£¼ ê°€ì¥ ì¢‹ì•˜ë˜ ê¸‰ì‹(2ê°œ ì„ íƒ), ì´ë²ˆì£¼ ê°€ì¥ ì‹«ì—ˆë˜ ê¸‰ì‹(1ê°œ ì„ íƒ)")
plot_weekday_meals(df, 'ì´ë²ˆì£¼ ê°€ì¥ ì¢‹ì•˜ë˜ ê¸‰ì‹', week_num=1, menus=week1_menus, title='(1ì£¼ì°¨)ì´ë²ˆì£¼ ê°€ì¥ ì¢‹ì•˜ë˜ ê¸‰ì‹')
plot_weekday_meals(df, 'ì´ë²ˆì£¼ ê°€ì¥ ì¢‹ì•˜ë˜ ê¸‰ì‹', week_num=2, menus=week2_menus, title='(2ì£¼ì°¨)ì´ë²ˆì£¼ ê°€ì¥ ì¢‹ì•˜ë˜ ê¸‰ì‹')
plot_weekday_meals(df, 'ì´ë²ˆì£¼ ê°€ì¥ ì¢‹ì•˜ë˜ ê¸‰ì‹', week_num=3, menus=week3_menus, title='(3ì£¼ì°¨)ì´ë²ˆì£¼ ê°€ì¥ ì¢‹ì•˜ë˜ ê¸‰ì‹')

plot_weekday_meals(df, 'ì´ë²ˆì£¼ ê°€ì¥ ì‹«ì—ˆë˜ ê¸‰ì‹', week_num=1, menus=week1_menus, title='(1ì£¼ì°¨)ì´ë²ˆì£¼ ê°€ì¥ ì‹«ì—ˆë˜ ê¸‰ì‹')
plot_weekday_meals(df, 'ì´ë²ˆì£¼ ê°€ì¥ ì‹«ì—ˆë˜ ê¸‰ì‹', week_num=2, menus=week2_menus, title='(2ì£¼ì°¨)ì´ë²ˆì£¼ ê°€ì¥ ì‹«ì—ˆë˜ ê¸‰ì‹')
 
dfl = pd.DataFrame({
    'ê¸‰ì‹ì„ ë‚¨ê¸°ëŠ” ì´ìœ ': [
        'ë§›ì´ì—†ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤',
        'ë©”ë‰´ì„ íƒì´ ì§„ì§œ ìµœì•…ì…ë‹ˆë‹¤. ì „ ì˜ì–‘ì‚¬ë¶„ë• ì•ˆ ê·¸ë¬ëŠ”ë°ìš”.. ë°¥ ì–‘ë„ ì¡°ê¸ˆ ì£¼ì‹œê³  ë°˜ì°¬ë„ ì¼ë¶€ëŸ¬ ì ê²Œ ì£¼ì‹œê³ .. ëŒ€êµ¬ê¹ŒìŠ¤ëŠ” ì§„ì§œë­¡ë‹ˆê¹Œ..ì•„ê·€ê°•ì •ë„ ë­ì˜ˆìš”â€¦ ì§„ì§œ ëª»ë¨¹ê² ì–´ìš” í•´ì‚°ë¬¼ ëª»ë¨¹ëŠ” ì¹œêµ¬ë“¤ì€ ì–´ì©Œë¼ê³  ì£¼ ë©”ë‰´ê°€ ì£„ë‹¤ í•´ì‚°ë¬¼ì¸ê°€ìš” ì§„ì§œ ìµœì•…ì…ë‹ˆë‹¤',
        'ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ',
        'ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë¶€ì‹¤í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì¢‹ì•„í•˜ì§€ ì•ŠëŠ” ë°˜ì°¬ì´ë¼ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤',
        'ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë©”ë‰´ê°€ ë³„ë¡œì—¬ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë§ì€ ê±´ ì•„ë‹ˆê³  ê·¸ëƒ¥ ë°°ë¶ˆëŸ¬ì„œ ë‚¨ê¸°ê²Œ ë˜ëŠ” ê²ƒ ê°™ì•„ìš©','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ',
        'ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì…ì— ì•ˆ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì¹œêµ¬ë“¤ì´ë‘ ë¹¨ë¦¬ ë†€ë ¤ê³ ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤',
        'ê°„ì´ ê³ ë“±í•™ìƒì¸ë° ì¡°ê¸ˆë§Œë” ìˆì—ˆìœ¼ë©´ ì¢‹ê²Ÿì–´ìš”','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë§›ì´ ì—†ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë‚´ê°€ ì•ˆì¢‹ì•„ í•˜ëŠ” ìŒì‹ì´ë¼ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ê±°ì˜ ë§¨ë‚  ë‹¤ ë¨¹ëŠ”ë‹¤',
        'ì•ˆ ë‚¨ê²¨ìš” ë§›ìˆì–´ìš”','ì‹«ì–´í•˜ê±°ë‚˜ ëª» ë¨¹ëŠ” ìŒì‹ë“¤ì´ ìˆì–´ì„œ','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ë§ì´ ë¨¹ê¸°ì—” ë¹¨ë¦¬ ì§ˆë¦¼','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë„ˆë¬´ ë§›ìˆëŠ”ë° ëˆ„ê°€ ë‚¨ê²¨ìš”','ì‹«ì–´í•˜ëŠ” ë©”ë‰´ê°€ ìˆì–´ì„œ',
        'ìœ ì œí’ˆì„ ëª» ë¨¹ìŒ','ì„ í˜¸í•˜ëŠ” ë©”ë‰´ê°€ ì•„ë‹ˆë¼ì„œ','ì–‘ì´ ë§ê³  ë¨¹ê³  ì‹¶ì€ ë©”ë‰´ê°€ ì—†ë‹¤ (ì¡°ê¸ˆë§Œ ë‹¬ë¼ê³  ë§ì”€ë“œë ¤ë„ ë§ì´ ì£¼ì‹œëŠ” ê²½ìš°ê°€ ìˆìŒ)','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë©”ë‰´ê°€ ë§ˆìŒì— ì•ˆë“¬','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤',
        'ì¢‹ì•„í•˜ì§€ ì•ŠëŠ” ìŒì‹ì´ì—¬ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','í€„ë¦¬í‹°ê°€ë‚®ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ê·¸ëƒ¥ ì•ˆë¨¹ê³ ì‹¶ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹«ì–´í•˜ëŠ” ìŒì‹ì€ ë‚¨ê¹€','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤',
        'ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë¨¹ì„ê²Œ ì—†ë‹¤','ë§›ì´ì—†ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ê³ ê¸°ë¥¼íŠ€ê¸´ê²Œì•„ë‹ˆë¼ í•­ìƒ ìƒì„ ì´ë‚˜ ë‘ë¶€ê°™ì€ê±¸ íŠ€ê¸°ë‹ˆê¹Œ ë§›ì—†ê³  ë‚¨ê²¨ìš” ê·¸ë¦¬ê³  ì°¸ì¹˜ë§ˆìš”ë°¥ í• ë•Œ ê¹»ì ì•ˆ ë„£ëŠ”ê²Œ ì¢‹ì„ê±°ê°™ì•„ìš” ì¹œêµ¬ë“¤ ë°˜ì‘ì´ í˜¸ë¶ˆí˜¸ê°€ ë„ˆë¬´ ë§ì´ ê°ˆë ¤ìš”',
        'ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì•ˆë‚¨ê¹€','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','êµ­ë¬¼ì€ ë‹¤ ëª» ë¨¹ì–´ìš”','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë§›ì´ ì—†ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë©”ë‰´ê°€ ë³„ë¡œì„','ë§›ì—†ìŒ',
        'ë§›ìˆëŠ” ê±´ ì¡°ê¸ˆ ì£¼ê³  ë§›ì—†ëŠ” ê±´ ë§ì´ ì¤˜ì„œ','ë°°ë¶ˆëŸ¬ì„œ','ë§›ì—†ìŒ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë§›ìˆëŠ”ê±´ ì ê²Œì£¼ê³  ë§›ì—†ëŠ”ê²ƒë§Œ ì—„ì²­ ë§ì´ ì¤˜ì„œ ë°¥ì´ë‘ ê°™ì´ ë¨¹ì„ê²Œ ì—†ë‹¤','ë¶€ì‹¤í•˜ê³  ë§›ì´ ì• ë§¤í•´ìš”ã… ','ìƒê°ë³´ë‹¤ ë§›ì—†ì–´ì„œ','ë§›ì—†ì–´ì„œ','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ',
        'ì¢‹ì•„í•˜ì§€ ì•ŠëŠ” ë©”ë‰´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë°°ë¶ˆëŸ¬ì„œ','ë§›ì´ì—†ì–´ì„œ','ë°¥ì€ ë§ì€ë° ë°˜ì°¬ì€ ë¶€ì¡±','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë§›ì—†ìŒ','ë§›ì—†ìŒ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë©”ë‰´ê°€ ë³„ë¡œì—¬ì„œ!','í¸ì‹','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤',
        'ë°˜ì°¬ì€ ì¡°ê¸ˆë§Œ ì£¼ëŠ”ë° ë°¥ì€ ë§ì´ ì¤˜ì„œ(ëŒ€ì²´ì ìœ¼ë¡œ ì ê²Œ ì¤Œ. ë°¥ì„ ì ê²Œ ë‹¬ë¼ëŠ”ê²Œ ì•„ë‹ˆë¼ ë±ì°¬ì„ ë§ì´ ë‹¬ë¼ëŠ” ëœ»ì…ë‹ˆë‹¤. ê³ ê¸° 3ì ë§Œ ì¤„ ë•Œë„ ìˆì—ˆì–´ìš”, ë” ë‹¬ë¼ê³ í•˜ë‹ˆ ì§œì¦ë‚´ì‹œê³ ...)','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤',
        'ë³„ë¡œ ì•ˆì¢‹ì•„í•˜ëŠ” ë©”ë‰´ë¼ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ'
    ]
})

# ì£¼ìš” 3ê°œ ì´ìœ 
main_reasons = ['ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ', 'ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤', 'ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤']

# ì¹´í…Œê³ ë¦¬ êµ¬ë¶„ í•¨ìˆ˜
def categorize_reason(text):
    if text in main_reasons:
        return text
    else:
        return 'ê¸°íƒ€'

dfl['ì¹´í…Œê³ ë¦¬'] = dfl['ê¸‰ì‹ì„ ë‚¨ê¸°ëŠ” ì´ìœ '].apply(categorize_reason)

# ì¹´í…Œê³ ë¦¬ë³„ ì‘ë‹µ ìˆ˜ ì§‘ê³„
counts = dfl['ì¹´í…Œê³ ë¦¬'].value_counts().reset_index()
counts.columns = ['ì´ìœ ', 'ì‘ë‹µ ìˆ˜']

# ë§‰ëŒ€ê·¸ë˜í”„ ì‹œê°í™”
fig = px.bar(
    counts,
    x='ì´ìœ ',
    y='ì‘ë‹µ ìˆ˜',
    title='ê¸‰ì‹ì„ ë‚¨ê¸°ëŠ” ì´ìœ ',
    labels={'ì´ìœ ': 'ì´ìœ ', 'ì‘ë‹µ ìˆ˜': 'ì‘ë‹µ ìˆ˜'}
)

st.plotly_chart(fig, use_container_width=True)

# ê¸°íƒ€ í•­ëª© ìƒì„¸ ë³´ê¸° (í¼ì¹˜ê¸°/ì ‘ê¸°)
other_texts = dfl[dfl['ì¹´í…Œê³ ë¦¬'] == 'ê¸°íƒ€']['ê¸‰ì‹ì„ ë‚¨ê¸°ëŠ” ì´ìœ '].tolist()

if other_texts:
    with st.expander("ê¸°íƒ€ í•­ëª© í¼ì¹˜ê¸° / ì ‘ê¸°"):
        st.markdown("**ê¸°íƒ€ì— í¬í•¨ëœ ì‘ë‹µ:**")
        for i, txt in enumerate(other_texts, 1):
            st.write(f"{i}. {txt}")


# ì„œìˆ í˜• ì‘ë‹µ ì²˜ë¦¬
def split_sentences(text):
    text = re.sub(r'[.?!]', '', text)
    return re.split(r',|ê·¸ë¦¬ê³ |ë˜ëŠ”|ë°|&|/|ë˜\s+|ê·¸ë¦¬ê³ \s+', text)

split_texts = []
original_indices = []
original_sentences = []

for idx, text in df['ì¶”ê°€ ë©”ë‰´ì™€ ê±´ì˜ì‚¬í•­'].dropna().astype(str).items():
    splits = split_sentences(text)
    for part in splits:
        cleaned = part.strip()
        if cleaned:
            split_texts.append(cleaned)
            original_indices.append(idx)
            original_sentences.append(text)

model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
model = model.to('cpu')
embeddings = model.encode(split_texts)

# êµ°ì§‘í™” ì‹¤í–‰
n_clusters = 7
kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
labels = kmeans.fit_predict(embeddings)

result_df = pd.DataFrame({
    'ë¬¸ì¥_ë¶„ì ˆ': split_texts,
    'êµ°ì§‘': labels,
    'ì›ë³¸ë¬¸ì¥_index': original_indices,
    'ì›ë³¸ë¬¸ì¥': original_sentences
})

st.write(f'\n=== [{'ì¶”ê°€ ë©”ë‰´ì™€ ê±´ì˜ì‚¬í•­'}] êµ°ì§‘í™” ê²°ê³¼ (êµ°ì§‘ ì´ë¦„ í¬í•¨) ===')
cluster_names = {}
for i in range(n_clusters):
    cluster_data = result_df[result_df['êµ°ì§‘'] == i]
    cluster_sentences = cluster_data['ë¬¸ì¥_ë¶„ì ˆ'].tolist()

    vectorizer = TfidfVectorizer(max_features=20, stop_words='english')
    tfidf_matrix = vectorizer.fit_transform(cluster_sentences)
    feature_names = vectorizer.get_feature_names_out()
    scores = tfidf_matrix.sum(axis=0).A1
    top_idx = scores.argmax()
    cluster_keyword = feature_names[top_idx]

    cluster_names[i] = cluster_keyword

    unique_originals = cluster_data[['ì›ë³¸ë¬¸ì¥']].drop_duplicates().reset_index(drop=True)
    with st.expander(f'[êµ°ì§‘ {i} - "{cluster_keyword}"] ì‘ë‹µ ë³´ê¸° (ì´ {len(unique_originals)}ê±´):'):
        for j, row in unique_originals.iterrows():
            st.write(f'- {row["ì›ë³¸ë¬¸ì¥"]}')

# êµ°ì§‘ë³„ ë¬¸ì¥ ìˆ˜ ì‹œê°í™”
result_df['êµ°ì§‘ëª…'] = result_df['êµ°ì§‘'].map(cluster_names)
cluster_counts = result_df['êµ°ì§‘ëª…'].value_counts().sort_values(ascending=False)
bar_df = cluster_counts.reset_index()
bar_df.columns = ['êµ°ì§‘ í‚¤ì›Œë“œ', 'ë¬¸ì¥ ìˆ˜']
fig = px.bar(bar_df, x='êµ°ì§‘ í‚¤ì›Œë“œ', y='ë¬¸ì¥ ìˆ˜', title='ì„œìˆ í˜• ì‘ë‹µ êµ°ì§‘ë³„ ë¬¸ì¥ ìˆ˜')
st.plotly_chart(fig)

st.write('ì‘ë‹µ ê²°ê³¼ ë¶„ì„')

# ğŸ“Œ CramÃ©r's V ê³„ì‚° í•¨ìˆ˜
def cramers_v(confusion_matrix):
    chi2 = chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.sum().sum()
    k = min(confusion_matrix.shape) - 1
    return np.sqrt(chi2 / (n * k))

# ğŸ“Œ ìƒê´€ê´€ê³„ ë¶„ì„ ë° ì‹œê°í™” í•¨ìˆ˜
def analyze_categorical_relationship(df, row_var, col_var, title):
   
    # 4. Stacked Bar Chartë¡œ ì‹œê°í™”
    st.markdown("### âœ… ì‘ë‹µë³„ ë¹„ìœ¨ ì‹œê°í™” (Stacked Bar Chart)")
    proportion_df = pd.crosstab(df[row_var], df[col_var], normalize='index') * 100
    fig = px.bar(
        proportion_df,
        x=proportion_df.index,
        y=proportion_df.columns,
        barmode='stack',
        text_auto='.1f',
        labels={'value': 'ë¹„ìœ¨ (%)', 'index': row_var, 'variable': col_var},
        title=f"{row_var}ì— ë”°ë¥¸ {col_var} ë¹„ìœ¨"
    )
    fig.update_layout(yaxis_title='ë¹„ìœ¨ (%)', xaxis_title=row_var)
    st.plotly_chart(fig, use_container_width=True)
       # 1. êµì°¨í‘œ ê³„ì‚°
    contingency = pd.crosstab(df[row_var], df[col_var])
    
    # 2. ì¹´ì´ì œê³± ë…ë¦½ì„± ê²€ì •
    chi2, p, dof, expected = chi2_contingency(contingency)
    v = cramers_v(contingency)

    # 3. ê²€ì • ê²°ê³¼ ì¶œë ¥
    st.markdown(f"**ChiÂ² í†µê³„ëŸ‰:** {chi2:.2f}")
    st.markdown(f"**p-value:** {p:.4f}")
    st.markdown(f"**CramÃ©r's V (ê´€ê³„ ê°•ë„):** {v:.3f}")
    if p < 0.05:
        st.success("âœ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„ì…ë‹ˆë‹¤.")
    else:
        st.info("â„¹ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„ëŠ” í™•ì¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def show_facet_bar(df, row_var, col_var, title):
    st.subheader(f"ğŸ“Š {title}")
    fig = px.histogram(df, x=col_var, color=row_var, barmode='group', text_auto=True)
    fig.update_layout(title=title, xaxis_title=col_var, yaxis_title='ì‘ë‹µ ìˆ˜')
    st.plotly_chart(fig, use_container_width=True)

       # 1. êµì°¨í‘œ ê³„ì‚°
    contingency = pd.crosstab(df[row_var], df[col_var])
    
    # 2. ì¹´ì´ì œê³± ë…ë¦½ì„± ê²€ì •
    chi2, p, dof, expected = chi2_contingency(contingency)
    v = cramers_v(contingency)

    # 3. ê²€ì • ê²°ê³¼ ì¶œë ¥
    st.markdown(f"**ChiÂ² í†µê³„ëŸ‰:** {chi2:.2f}")
    st.markdown(f"**p-value:** {p:.4f}")
    st.markdown(f"**CramÃ©r's V (ê´€ê³„ ê°•ë„):** {v:.3f}")
    if p < 0.05:
        st.success("âœ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„ì…ë‹ˆë‹¤.")
    else:
        st.info("â„¹ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„ëŠ” í™•ì¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def show_grouped_bar(df, row_var, col_var, title):
    st.subheader(f"ğŸ“Š {title}")
        
    ctab = pd.crosstab(df[row_var], df[col_var])
    ctab = ctab[sorted(ctab.columns)]  # ì—´ ì •ë ¬

    fig = px.bar(
        ctab,
        x=ctab.index,
        y=ctab.columns,
        barmode='group',
        title=title,
        labels={'value': 'ì‘ë‹µ ìˆ˜', 'index': row_var},
        text_auto=True
    )
    fig.update_layout(xaxis_title=row_var, yaxis_title='ì‘ë‹µ ìˆ˜')
    st.plotly_chart(fig, use_container_width=True)
       # 1. êµì°¨í‘œ ê³„ì‚°
    contingency = pd.crosstab(df[row_var], df[col_var])
    
    # 2. ì¹´ì´ì œê³± ë…ë¦½ì„± ê²€ì •
    chi2, p, dof, expected = chi2_contingency(contingency)
    v = cramers_v(contingency)

    # 3. ê²€ì • ê²°ê³¼ ì¶œë ¥
    st.markdown(f"**ChiÂ² í†µê³„ëŸ‰:** {chi2:.2f}")
    st.markdown(f"**p-value:** {p:.4f}")
    st.markdown(f"**CramÃ©r's V (ê´€ê³„ ê°•ë„):** {v:.3f}")
    if p < 0.05:
        st.success("âœ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„ì…ë‹ˆë‹¤.")
    else:
        st.info("â„¹ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„ëŠ” í™•ì¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

analyze_categorical_relationship(df, 'ì•„ì¹¨ë°¥', 'ì´ë²ˆì£¼ ë§Œì¡±ë„', 'ì•„ì¹¨ë°¥ ì—¬ë¶€ì™€ ë§Œì¡±ë„ ê´€ê³„')
show_facet_bar(df, 'ì”ë°˜ ë¹„ìœ¨', 'ìˆ˜ë©´ì‹œê°„', 'ìˆ˜ë©´ì‹œê°„ê³¼ ì”ë°˜ ë¹„ìœ¨ ê´€ê³„')
analyze_categorical_relationship(df, 'ìˆ˜ë©´ì‹œê°„', 'ì´ë²ˆì£¼ ë§Œì¡±ë„', 'ìˆ˜ë©´ì‹œê°„ê³¼ ë§Œì¡±ë„ ê´€ê³„')
show_grouped_bar(df, 'ì”ë°˜ ë¹„ìœ¨', 'ì´ë²ˆì£¼ ë§Œì¡±ë„', 'ì•„ì¹¨ë°¥ ì—¬ë¶€ì™€ ë§Œì¡±ë„ ê´€ê³„')
