# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
from sentence_transformers import SentenceTransformer
from sklearn.cluster import KMeans
from scipy.stats import chi2_contingency
import numpy as np
from sklearn.decomposition import PCA
from matplotlib import font_manager
import urllib.request
import os
import plotly.express as px

file_path = 'ê¸‰ì‹ ì„¤ë¬¸ì¡°ì‚¬ ì „ì²´-1.csv'
df = pd.read_csv(file_path, encoding='utf-8')

st.write('ê¸‰ì‹ ì„¤ë¬¸ì¡°ì‚¬ ì‘ë‹µ ê²°ê³¼/ê²°ê³¼ ë¶„ì„')

# ê°ê´€ì‹ í•­ëª© ì‹œê°í™”
objective_columns = ['í•™ë…„']
for col in objective_columns:
    if col in df.columns:
        value_counts = df[col].value_counts().reset_index()
        value_counts.columns = [col, 'ì‘ë‹µ ìˆ˜']
        fig = px.bar(value_counts, x=col, y='ì‘ë‹µ ìˆ˜', title=f'{col} ì‘ë‹µ ë¶„í¬')
        st.plotly_chart(fig)

for col in ['ì´ë²ˆì£¼ ë§Œì¡±ë„']:
    if col in df.columns:
        pie_data = df[col].value_counts().reset_index()
        pie_data.columns = [col, 'ë¹„ìœ¨']
        fig = px.pie(pie_data, names=col, values='ë¹„ìœ¨', title=f'{col} ë¹„ìœ¨', hole=0.4)
        st.plotly_chart(fig)

objective_columns = ['ì”ë°˜ ë¹„ìœ¨', 'ìˆ˜ë©´ì‹œê°„']
for col in objective_columns:
    if col in df.columns:
        value_counts = df[col].value_counts().reset_index()
        value_counts.columns = [col, 'ì‘ë‹µ ìˆ˜']
        fig = px.bar(value_counts, x=col, y='ì‘ë‹µ ìˆ˜', title=f'{col} ì‘ë‹µ ë¶„í¬')
        st.plotly_chart(fig)
        
# íŒŒì´ ì°¨íŠ¸ ì‹œê°í™”
for col in ['ì´ë²ˆì£¼ ê¸‰ì‹ì´ ì¢‹ì•˜ë˜ ì´ìœ ','ê¸‰ì‹ì„ ë¨¹ì§€ ì•Šì€ ì´ìœ ','ì•„ì¹¨ë°¥']:
    if col in df.columns:
        pie_data = df[col].value_counts().reset_index()
        pie_data.columns = [col, 'ë¹„ìœ¨']
        fig = px.pie(pie_data, names=col, values='ë¹„ìœ¨', title=f'{col} ë¹„ìœ¨', hole=0.4)
        st.plotly_chart(fig)

if 'ì´ë²ˆì£¼ ê°€ì¥ ì¢‹ì•˜ë˜ ê¸‰ì‹'and'ì´ë²ˆì£¼ ê°€ì¥ ì‹«ì—ˆë˜ ê¸‰ì‹' in df.columns:
     
    week1_menus = [
    "ì›”ìš”ì¼ - ë§ˆë¼íƒ•, ë¯¸ë‹ˆìœ¡ì „, ì´ˆì½”ìš°ìœ ","ê¸ˆìš”ì¼ - ì°¸ì¹˜ë§ˆìš”ë®ë°¥, í¬ë¦¬ìŠ¤í”¼ ë‘ë¶€ìŠ¤í‹±,ê¹”ë¼ë§Œì‹œë ˆëª¬ì—ì´ë“œ", "í™”ìš”ì¼ - ìˆœëŒ€êµ­, ëŒ€êµ¬ê¹ŒìŠ¤, íŒŒì¸ì• í”Œ","ìˆ˜ìš”ì¼ - ì¹˜í‚¨ê¿”ë°”ë¡œìš°, ì°¹ìŒ€ì•½ê³¼", "ëª©ìš”ì¼- ì°¹ìŠ¤í…Œì´í¬, ì‚°ì–‘ìš”êµ¬ë¥´íŠ¸"
]
    week2_menus = [
    "ì›”ìš”ì¼ - ì „ì£¼ì‹ì½©ë‚˜ë¬¼êµ­ë°¥, ëœì¥ë¶ˆê³ ê¸°, ë°”ë‚˜ë‚˜ìš°ìœ ", "í™”ìš”ì¼ - ëƒ‰ë©”ë°€êµ­ìˆ˜, ì•Œë°¥, ëˆê°€ìŠ¤, íƒ€ì½”ì•¼ë¼, ì£¼ìŠ¤", "ìˆ˜ìš”ì¼ - ìœ¡ê°œì¥, íƒ•í‰ì±„, ì›…ë–¡ì›…ë–¡, ë¼ì„ë ˆëª¬ì£¼ìŠ¤","ê¸ˆìš”ì¼ - ë¶€ëŒ€ì°Œê°œ, ë‹­ë´‰ë°ë¦¬ì•¼ë¼êµ¬ì´, ìš”êµ¬ë¥´íŠ¸(ì• í”Œë§ê³ )", "ëª©ìš”ì¼- ì¹´ë ˆë¼ì´ìŠ¤, ì™•ë§Œë‘, íë¸Œì¹´í”„ë ˆì œ, ê°ììŠ¤ë‚µ"
]
    week3_menus = [
    "ì›”ìš”ì¼ - ìƒˆìš°ë² ì´ì»¨ë³¶ìŒë°¥, ê°ììƒëŸ¬ë“œ, ëª¨ë‹ë¹µ, ìëª½ì—ì´ë“œ", "í™”ìš”ì¼ - ëŒ€íŒ¨ì‚¼ê²¹ë²„ì„¯êµ¬ì´, ìš”êµ¬ë¥´íŠ¸", "ìˆ˜ìš”ì¼ - ì”ì¹˜êµ­ìˆ˜, ì˜¤ë¦¬ì£¼ë¬¼ëŸ­, íŒŒì¸ì• í”Œ","ëª©ìš”ì¼- ê°ˆë¹„íƒ•, ì˜¤ì§•ì–´ê¹€ì¹˜ì „, ë³µìˆ­ì•„ì£¼ìŠ¤", "ê¸ˆìš”ì¼ - ë‹­ê°ˆë¹„, ì´ìƒí•œë‚˜ë¼ì˜ì†œì‚¬íƒ•ì•„ì´ìŠ¤í¬ë¦¼"
]
    menu_col = df['ì´ë²ˆì£¼ ê°€ì¥ ì¢‹ì•˜ë˜ ê¸‰ì‹'].dropna().astype(str)
    
    week1 = menu_col[menu_col.apply(lambda x: any(menu in x for menu in week1_menus))]
    week2 = menu_col[menu_col.apply(lambda x: any(menu in x for menu in week2_menus))]
    week3 = menu_col[menu_col.apply(lambda x: any(menu in x for menu in week3_menus))]

    week_data = {
        '1ì£¼ì°¨': week1,
        '2ì£¼ì°¨': week2,
        '3ì£¼ì°¨': week3
    }

    for week_name, data in week_data.items():
        value_counts = data.value_counts().reset_index()
        value_counts.columns = ['ê¸‰ì‹', 'ì‘ë‹µ ìˆ˜']
        fig = px.bar(
            value_counts,
            x='ê¸‰ì‹', y='ì‘ë‹µ ìˆ˜',
            title=f'[{week_name}] ê°€ì¥ ì¢‹ì•˜ë˜ ê¸‰ì‹', 
            labels={'ê¸‰ì‹': 'ê¸‰ì‹ ë©”ë‰´'}
        )
        st.plotly_chart(fig)   
        
    menu_col = df['ì´ë²ˆì£¼ ê°€ì¥ ì‹«ì—ˆë˜ ê¸‰ì‹'].dropna().astype(str)
    
    week1 = menu_col[menu_col.apply(lambda x: any(menu in x for menu in week1_menus))]
    week2 = menu_col[menu_col.apply(lambda x: any(menu in x for menu in week2_menus))]
   

    week_data = {
        '1ì£¼ì°¨': week1,
        '2ì£¼ì°¨': week2
    }

    for week_name, data in week_data.items():
        value_counts = data.value_counts().reset_index()
        value_counts.columns = ['ê¸‰ì‹', 'ì‘ë‹µ ìˆ˜']
        fig = px.bar(
            value_counts,
            x='ê¸‰ì‹', y='ì‘ë‹µ ìˆ˜',
            title=f'[{week_name}] ê°€ì¥ ì‹«ì—ˆë˜ ê¸‰ì‹', 
            labels={'ê¸‰ì‹': 'ê¸‰ì‹ ë©”ë‰´'}
        )
        st.plotly_chart(fig)

 
dfl = pd.DataFrame({
    'ê¸‰ì‹ì„ ë‚¨ê¸°ëŠ” ì´ìœ ': [
        'ë§›ì´ì—†ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤',
        'ë©”ë‰´ì„ íƒì´ ì§„ì§œ ìµœì•…ì…ë‹ˆë‹¤. ì „ ì˜ì–‘ì‚¬ë¶„ë• ì•ˆ ê·¸ë¬ëŠ”ë°ìš”.. ë°¥ ì–‘ë„ ì¡°ê¸ˆ ì£¼ì‹œê³  ë°˜ì°¬ë„ ì¼ë¶€ëŸ¬ ì ê²Œ ì£¼ì‹œê³ .. ëŒ€êµ¬ê¹ŒìŠ¤ëŠ” ì§„ì§œë­¡ë‹ˆê¹Œ..ì•„ê·€ê°•ì •ë„ ë­ì˜ˆìš”â€¦ ì§„ì§œ ëª»ë¨¹ê² ì–´ìš” í•´ì‚°ë¬¼ ëª»ë¨¹ëŠ” ì¹œêµ¬ë“¤ì€ ì–´ì©Œë¼ê³  ì£¼ ë©”ë‰´ê°€ ì£„ë‹¤ í•´ì‚°ë¬¼ì¸ê°€ìš” ì§„ì§œ ìµœì•…ì…ë‹ˆë‹¤',
        'ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ',
        'ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë¶€ì‹¤í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì¢‹ì•„í•˜ì§€ ì•ŠëŠ” ë°˜ì°¬ì´ë¼ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤',
        'ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë©”ë‰´ê°€ ë³„ë¡œì—¬ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë§ì€ ê±´ ì•„ë‹ˆê³  ê·¸ëƒ¥ ë°°ë¶ˆëŸ¬ì„œ ë‚¨ê¸°ê²Œ ë˜ëŠ” ê²ƒ ê°™ì•„ìš©','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ',
        'ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì…ì— ì•ˆ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì¹œêµ¬ë“¤ì´ë‘ ë¹¨ë¦¬ ë†€ë ¤ê³ ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤',
        'ê°„ì´ ê³ ë“±í•™ìƒì¸ë° ì¡°ê¸ˆë§Œë” ìˆì—ˆìœ¼ë©´ ì¢‹ê²Ÿì–´ìš”','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë§›ì´ ì—†ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë‚´ê°€ ì•ˆì¢‹ì•„ í•˜ëŠ” ìŒì‹ì´ë¼ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ê±°ì˜ ë§¨ë‚  ë‹¤ ë¨¹ëŠ”ë‹¤',
        'ì•ˆ ë‚¨ê²¨ìš” ë§›ìˆì–´ìš”','ì‹«ì–´í•˜ê±°ë‚˜ ëª» ë¨¹ëŠ” ìŒì‹ë“¤ì´ ìˆì–´ì„œ','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ë§ì´ ë¨¹ê¸°ì—” ë¹¨ë¦¬ ì§ˆë¦¼','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë„ˆë¬´ ë§›ìˆëŠ”ë° ëˆ„ê°€ ë‚¨ê²¨ìš”','ì‹«ì–´í•˜ëŠ” ë©”ë‰´ê°€ ìˆì–´ì„œ',
        'ìœ ì œí’ˆì„ ëª» ë¨¹ìŒ','ì„ í˜¸í•˜ëŠ” ë©”ë‰´ê°€ ì•„ë‹ˆë¼ì„œ','ì–‘ì´ ë§ê³  ë¨¹ê³  ì‹¶ì€ ë©”ë‰´ê°€ ì—†ë‹¤ (ì¡°ê¸ˆë§Œ ë‹¬ë¼ê³  ë§ì”€ë“œë ¤ë„ ë§ì´ ì£¼ì‹œëŠ” ê²½ìš°ê°€ ìˆìŒ)','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë©”ë‰´ê°€ ë§ˆìŒì— ì•ˆë“¬','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤',
        'ì¢‹ì•„í•˜ì§€ ì•ŠëŠ” ìŒì‹ì´ì—¬ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','í€„ë¦¬í‹°ê°€ë‚®ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ê·¸ëƒ¥ ì•ˆë¨¹ê³ ì‹¶ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹«ì–´í•˜ëŠ” ìŒì‹ì€ ë‚¨ê¹€','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤',
        'ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë¨¹ì„ê²Œ ì—†ë‹¤','ë§›ì´ì—†ë‹¤','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ê³ ê¸°ë¥¼íŠ€ê¸´ê²Œì•„ë‹ˆë¼ í•­ìƒ ìƒì„ ì´ë‚˜ ë‘ë¶€ê°™ì€ê±¸ íŠ€ê¸°ë‹ˆê¹Œ ë§›ì—†ê³  ë‚¨ê²¨ìš” ê·¸ë¦¬ê³  ì°¸ì¹˜ë§ˆìš”ë°¥ í• ë•Œ ê¹»ì ì•ˆ ë„£ëŠ”ê²Œ ì¢‹ì„ê±°ê°™ì•„ìš” ì¹œêµ¬ë“¤ ë°˜ì‘ì´ í˜¸ë¶ˆí˜¸ê°€ ë„ˆë¬´ ë§ì´ ê°ˆë ¤ìš”',
        'ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì•ˆë‚¨ê¹€','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','êµ­ë¬¼ì€ ë‹¤ ëª» ë¨¹ì–´ìš”','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë§›ì´ ì—†ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë©”ë‰´ê°€ ë³„ë¡œì„','ë§›ì—†ìŒ',
        'ë§›ìˆëŠ” ê±´ ì¡°ê¸ˆ ì£¼ê³  ë§›ì—†ëŠ” ê±´ ë§ì´ ì¤˜ì„œ','ë°°ë¶ˆëŸ¬ì„œ','ë§›ì—†ìŒ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë§›ìˆëŠ”ê±´ ì ê²Œì£¼ê³  ë§›ì—†ëŠ”ê²ƒë§Œ ì—„ì²­ ë§ì´ ì¤˜ì„œ ë°¥ì´ë‘ ê°™ì´ ë¨¹ì„ê²Œ ì—†ë‹¤','ë¶€ì‹¤í•˜ê³  ë§›ì´ ì• ë§¤í•´ìš”ã… ','ìƒê°ë³´ë‹¤ ë§›ì—†ì–´ì„œ','ë§›ì—†ì–´ì„œ','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ',
        'ì¢‹ì•„í•˜ì§€ ì•ŠëŠ” ë©”ë‰´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ë°°ë¶ˆëŸ¬ì„œ','ë§›ì´ì—†ì–´ì„œ','ë°¥ì€ ë§ì€ë° ë°˜ì°¬ì€ ë¶€ì¡±','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë§›ì—†ìŒ','ë§›ì—†ìŒ','ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë©”ë‰´ê°€ ë³„ë¡œì—¬ì„œ!','í¸ì‹','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤',
        'ë°˜ì°¬ì€ ì¡°ê¸ˆë§Œ ì£¼ëŠ”ë° ë°¥ì€ ë§ì´ ì¤˜ì„œ(ëŒ€ì²´ì ìœ¼ë¡œ ì ê²Œ ì¤Œ. ë°¥ì„ ì ê²Œ ë‹¬ë¼ëŠ”ê²Œ ì•„ë‹ˆë¼ ë±ì°¬ì„ ë§ì´ ë‹¬ë¼ëŠ” ëœ»ì…ë‹ˆë‹¤. ê³ ê¸° 3ì ë§Œ ì¤„ ë•Œë„ ìˆì—ˆì–´ìš”, ë” ë‹¬ë¼ê³ í•˜ë‹ˆ ì§œì¦ë‚´ì‹œê³ ...)','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ','ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤',
        'ë³„ë¡œ ì•ˆì¢‹ì•„í•˜ëŠ” ë©”ë‰´ë¼ì„œ','ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ'
    ]
})

# ì£¼ìš” 3ê°œ ì´ìœ 
main_reasons = ['ì–‘ì´ ë„ˆë¬´ ë§ì•„ì„œ', 'ë„ˆë¬´ ì§œê±°ë‚˜ ì‹±ê²ë‹¤', 'ì‹œê°„ì´ ë¶€ì¡±í•˜ë‹¤']

# ì¹´í…Œê³ ë¦¬ êµ¬ë¶„ í•¨ìˆ˜
def categorize_reason(text):
    if text in main_reasons:
        return text
    else:
        return 'ê¸°íƒ€'

dfl['ì¹´í…Œê³ ë¦¬'] = dfl['ê¸‰ì‹ì„ ë‚¨ê¸°ëŠ” ì´ìœ '].apply(categorize_reason)

# ì¹´í…Œê³ ë¦¬ë³„ ì‘ë‹µ ìˆ˜ ì§‘ê³„
counts = dfl['ì¹´í…Œê³ ë¦¬'].value_counts().reset_index()
counts.columns = ['ì´ìœ ', 'ì‘ë‹µ ìˆ˜']

# ë§‰ëŒ€ê·¸ë˜í”„ ì‹œê°í™”
fig = px.bar(
    counts,
    x='ì´ìœ ',
    y='ì‘ë‹µ ìˆ˜',
    title='ê¸‰ì‹ì„ ë‚¨ê¸°ëŠ” ì´ìœ ',
    labels={'ì´ìœ ': 'ì´ìœ ', 'ì‘ë‹µ ìˆ˜': 'ì‘ë‹µ ìˆ˜'}
)

st.plotly_chart(fig, use_container_width=True)

# ê¸°íƒ€ í•­ëª© ìƒì„¸ ë³´ê¸° (í¼ì¹˜ê¸°/ì ‘ê¸°)
other_texts = dfl[dfl['ì¹´í…Œê³ ë¦¬'] == 'ê¸°íƒ€']['ê¸‰ì‹ì„ ë‚¨ê¸°ëŠ” ì´ìœ '].tolist()

if other_texts:
    with st.expander("ê¸°íƒ€ í•­ëª© í¼ì¹˜ê¸° / ì ‘ê¸°"):
        st.markdown("**ê¸°íƒ€ì— í¬í•¨ëœ ì‘ë‹µ:**")
        for i, txt in enumerate(other_texts, 1):
            st.write(f"{i}. {txt}")

# ------------------ 1. ë¬¸ì¥ ë¶„ë¦¬ í•¨ìˆ˜ ------------------
def split_sentences(text):
    text = re.sub(r'[.?!]', '', text)
    return re.split(r',|ê·¸ë¦¬ê³ |ë˜ëŠ”|ë°|&|/|ë˜\s+|ê·¸ë¦¬ê³ \s+', text)

# ------------------ 2. êµ°ì§‘í™” ì‹œê°í™” í•¨ìˆ˜ ------------------
def cluster_text_responses(df, text_column, n_clusters=10, top_n=5):
    st.subheader("ê±´ì˜ì‚¬í•­ ì‘ë‹µ êµ°ì§‘ ë¶„ì„")

    # ë¬¸ì¥ ë¶„ë¦¬
    sentences = []
    for response in df[text_column].dropna().astype(str):
        for s in split_sentences(response):
            s_clean = s.strip()
            if s_clean:
                sentences.append(s_clean)

    if not sentences:
        st.warning("ìœ íš¨í•œ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë¬¸ì¥ ì„ë² ë”©
    with st.spinner("ë¬¸ì¥ ì„ë² ë”© ì¤‘..."):
        model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device='cpu')
        embeddings = model.encode(sentences)

    # êµ°ì§‘í™”
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(embeddings)

    # êµ°ì§‘ë³„ ë¬¸ì¥ ëª¨ìŒ
    cluster_sentences = {i: [] for i in range(n_clusters)}
    for label, sentence in zip(labels, sentences):
        cluster_sentences[label].append(sentence)

    # TF-IDF í‚¤ì›Œë“œ ì¶”ì¶œ
    cluster_keywords = {}
    for cluster, sents in cluster_sentences.items():
        vectorizer = TfidfVectorizer(stop_words='english', max_features=1)
        X = vectorizer.fit_transform(sents)
        keywords = vectorizer.get_feature_names_out()
        cluster_keywords[cluster] = keywords[0] if len(keywords) > 0 else "ê¸°íƒ€"

    # êµ°ì§‘ë³„ ì‘ë‹µ ìˆ˜
    counts = pd.Series(labels).value_counts().sort_values(ascending=False)
    top_clusters = counts.head(top_n).index

    df_plot = pd.DataFrame({
        'êµ°ì§‘': [f'Cluster {i}' for i in top_clusters],
        'ëŒ€í‘œ í‚¤ì›Œë“œ': [", ".join(cluster_keywords[i]) for i in top_clusters],
        'ì‘ë‹µ ìˆ˜': [counts[i] for i in top_clusters]
    })

    # ì‹œê°í™”
    fig = px.bar(
        df_plot,
        x='ëŒ€í‘œ í‚¤ì›Œë“œ',
        y='ì‘ë‹µ ìˆ˜',
        text='ì‘ë‹µ ìˆ˜',
        hover_data={'ëŒ€í‘œ í‚¤ì›Œë“œ': True},
        title=f'ê±´ì˜ì‚¬í•­ ì‘ë‹µ ìƒìœ„ {top_n}ê°œ êµ°ì§‘',
    )
    fig.update_traces(textposition='outside')
    fig.update_layout(yaxis_title="ì‘ë‹µ ìˆ˜", xaxis_title="êµ°ì§‘", hovermode="x unified")
    st.plotly_chart(fig, use_container_width=True)

    # ëª¨ë“  êµ°ì§‘ ì„¸ë¶€ ë‚´ìš© ë³´ê¸°
    st.markdown("### ğŸ“‹ ëª¨ë“  êµ°ì§‘ë³„ ì›ë¬¸ ì‘ë‹µ ë³´ê¸°")
    for cluster in sorted(cluster_sentences.keys()):
        with st.expander(f"Cluster {cluster} â€“ í‚¤ì›Œë“œ: {', '.join(cluster_keywords[cluster])}"):
            for s in cluster_sentences[cluster]:
                st.markdown(f"- {s}")

if 'ì¶”ê°€ ë©”ë‰´ì™€ ê±´ì˜ì‚¬í•­' in df.columns:
    cluster_text_responses(df, text_column='ì¶”ê°€ ë©”ë‰´ì™€ ê±´ì˜ì‚¬í•­')
else:
    st.warning("ë°ì´í„°í”„ë ˆì„ì— 'ì¶”ê°€ ë©”ë‰´ì™€ ê±´ì˜ì‚¬í•­' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")


st.write('ì‘ë‹µ ê²°ê³¼ ë¶„ì„')

# ğŸ“Œ CramÃ©r's V ê³„ì‚° í•¨ìˆ˜
def cramers_v(confusion_matrix):
    chi2 = chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.sum().sum()
    k = min(confusion_matrix.shape) - 1
    return np.sqrt(chi2 / (n * k))

# ğŸ“Œ ìƒê´€ê´€ê³„ ë¶„ì„ ë° ì‹œê°í™” í•¨ìˆ˜
def analyze_categorical_relationship(df, row_var, col_var, title):
   
    # 4. Stacked Bar Chartë¡œ ì‹œê°í™”
    st.markdown("### âœ… ì‘ë‹µë³„ ë¹„ìœ¨ ì‹œê°í™” (Stacked Bar Chart)")
    proportion_df = pd.crosstab(df[row_var], df[col_var], normalize='index') * 100
    fig = px.bar(
        proportion_df,
        x=proportion_df.index,
        y=proportion_df.columns,
        barmode='stack',
        text_auto='.1f',
        labels={'value': 'ë¹„ìœ¨ (%)', 'index': row_var, 'variable': col_var},
        title=f"{row_var}ì— ë”°ë¥¸ {col_var} ë¹„ìœ¨"
    )
    fig.update_layout(yaxis_title='ë¹„ìœ¨ (%)', xaxis_title=row_var)
    st.plotly_chart(fig, use_container_width=True)
       # 1. êµì°¨í‘œ ê³„ì‚°
    contingency = pd.crosstab(df[row_var], df[col_var])
    
    # 2. ì¹´ì´ì œê³± ë…ë¦½ì„± ê²€ì •
    chi2, p, dof, expected = chi2_contingency(contingency)
    v = cramers_v(contingency)

    # 3. ê²€ì • ê²°ê³¼ ì¶œë ¥
    st.markdown(f"**ChiÂ² í†µê³„ëŸ‰:** {chi2:.2f}")
    st.markdown(f"**p-value:** {p:.4f}")
    st.markdown(f"**CramÃ©r's V (ê´€ê³„ ê°•ë„):** {v:.3f}")
    if p < 0.05:
        st.success("âœ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„ì…ë‹ˆë‹¤.")
    else:
        st.info("â„¹ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„ëŠ” í™•ì¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def show_facet_bar(df, row_var, col_var, title):
    st.subheader(f"ğŸ“Š {title}")
    fig = px.histogram(df, x=col_var, color=row_var, barmode='group', text_auto=True)
    fig.update_layout(title=title, xaxis_title=col_var, yaxis_title='ì‘ë‹µ ìˆ˜')
    st.plotly_chart(fig, use_container_width=True)

       # 1. êµì°¨í‘œ ê³„ì‚°
    contingency = pd.crosstab(df[row_var], df[col_var])
    
    # 2. ì¹´ì´ì œê³± ë…ë¦½ì„± ê²€ì •
    chi2, p, dof, expected = chi2_contingency(contingency)
    v = cramers_v(contingency)

    # 3. ê²€ì • ê²°ê³¼ ì¶œë ¥
    st.markdown(f"**ChiÂ² í†µê³„ëŸ‰:** {chi2:.2f}")
    st.markdown(f"**p-value:** {p:.4f}")
    st.markdown(f"**CramÃ©r's V (ê´€ê³„ ê°•ë„):** {v:.3f}")
    if p < 0.05:
        st.success("âœ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„ì…ë‹ˆë‹¤.")
    else:
        st.info("â„¹ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„ëŠ” í™•ì¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def show_grouped_bar(df, row_var, col_var, title):
    st.subheader(f"ğŸ“Š {title}")
        
    ctab = pd.crosstab(df[row_var], df[col_var])
    ctab = ctab[sorted(ctab.columns)]  # ì—´ ì •ë ¬

    fig = px.bar(
        ctab,
        x=ctab.index,
        y=ctab.columns,
        barmode='group',
        title=title,
        labels={'value': 'ì‘ë‹µ ìˆ˜', 'index': row_var},
        text_auto=True
    )
    fig.update_layout(xaxis_title=row_var, yaxis_title='ì‘ë‹µ ìˆ˜')
    st.plotly_chart(fig, use_container_width=True)
       # 1. êµì°¨í‘œ ê³„ì‚°
    contingency = pd.crosstab(df[row_var], df[col_var])
    
    # 2. ì¹´ì´ì œê³± ë…ë¦½ì„± ê²€ì •
    chi2, p, dof, expected = chi2_contingency(contingency)
    v = cramers_v(contingency)

    # 3. ê²€ì • ê²°ê³¼ ì¶œë ¥
    st.markdown(f"**ChiÂ² í†µê³„ëŸ‰:** {chi2:.2f}")
    st.markdown(f"**p-value:** {p:.4f}")
    st.markdown(f"**CramÃ©r's V (ê´€ê³„ ê°•ë„):** {v:.3f}")
    if p < 0.05:
        st.success("âœ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„ì…ë‹ˆë‹¤.")
    else:
        st.info("â„¹ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„ëŠ” í™•ì¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

analyze_categorical_relationship(df, 'ì•„ì¹¨ë°¥', 'ì´ë²ˆì£¼ ë§Œì¡±ë„', 'ì•„ì¹¨ë°¥ ì—¬ë¶€ì™€ ë§Œì¡±ë„ ê´€ê³„')
show_facet_bar(df, 'ì”ë°˜ ë¹„ìœ¨', 'ìˆ˜ë©´ì‹œê°„', 'ìˆ˜ë©´ì‹œê°„ê³¼ ì”ë°˜ ë¹„ìœ¨ ê´€ê³„')
analyze_categorical_relationship(df, 'ìˆ˜ë©´ì‹œê°„', 'ì´ë²ˆì£¼ ë§Œì¡±ë„', 'ìˆ˜ë©´ì‹œê°„ê³¼ ë§Œì¡±ë„ ê´€ê³„')
show_grouped_bar(df, 'ì”ë°˜ ë¹„ìœ¨', 'ì´ë²ˆì£¼ ë§Œì¡±ë„', 'ì•„ì¹¨ë°¥ ì—¬ë¶€ì™€ ë§Œì¡±ë„ ê´€ê³„')
st.write('ë¶„ì„ ê²°ê³¼ ì”ë°˜ì´ ë§ì€ í•™ìƒì¼ìˆ˜ë¡ ê¸‰ì‹ì— ëŒ€í•œ ë§Œì¡±ë„ê°€ ë‚®ìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤')
